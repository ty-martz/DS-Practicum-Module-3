{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 10: Linear Algebra\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task:\n",
    "\n",
    "- The Sure Tomorrow insurance company wants to protect its clients' data. Your task is to develop a data transforming algorithm that would make it hard to recover personal information from the transformed data. This is called data masking, or data obfuscation. You are also expected to prove that the algorithm works correctly. Additionally, the data should be protected in such a way that the quality of machine learning models doesn't suffer. You don't need to pick the best model.\n",
    "- Follow these steps to develop a new algorithm:\n",
    "    - construct a theoretical proof using properties of models and the given task;\n",
    "    - formulate an algorithm for this proof;\n",
    "    - check that the algorithm is working correctly when applied to real data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Instructions:\n",
    "\n",
    "- Look into and preprocess the data.\n",
    "- Provide a theoretical proof based on the equation of linear regression.\n",
    "    - The features are multiplied by an invertible matrix. Show that the quality of the model is the same for both sets of parameters: the original features and the features after multiplication.\n",
    "    - How are the weight vectors from MSE minimums for these models related?\n",
    "- State an algorithm for data transformation to solve the task. Explain why the linear regression quality won't change based on the proof above.\n",
    "- Program your algorithm using matrix operations. Make sure that the quality of linear regression from sklearn is the same before and after transformation. Use the R2 metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data:\n",
    "- Insurance Data in the US\n",
    "- Each row is a single record for a person on insurance\n",
    "- Columns:\n",
    "    - Features: insured person's gender, age, salary, and number of family members.\n",
    "    - Target: number of insurance benefits received by the insured person over the last five years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Look into and Preprocess the Data:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Family members</th>\n",
       "      <th>Insurance benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age   Salary  Family members  Insurance benefits\n",
       "0       1  41.0  49600.0               1                   0\n",
       "1       0  46.0  38000.0               1                   1\n",
       "2       0  29.0  21000.0               0                   0\n",
       "3       0  21.0  41700.0               2                   0\n",
       "4       1  28.0  26100.0               0                   0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data to a pandas dataframe\n",
    "\n",
    "# Local Path\n",
    "#df = pd.read_csv('insurance_us.csv')\n",
    "\n",
    "# Practicum JupyterHub Path\n",
    "df = pd.read_csv('/datasets/insurance_us.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['gender', 'age', 'salary', 'family_members', 'insurance_benefits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      "gender                5000 non-null int64\n",
      "age                   5000 non-null float64\n",
      "salary                5000 non-null float64\n",
      "family_members        5000 non-null int64\n",
      "insurance_benefits    5000 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>30.952800</td>\n",
       "      <td>39916.360000</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.440807</td>\n",
       "      <td>9900.083569</td>\n",
       "      <td>1.091387</td>\n",
       "      <td>0.463183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age        salary  family_members  \\\n",
       "count  5000.000000  5000.000000   5000.000000     5000.000000   \n",
       "mean      0.499000    30.952800  39916.360000        1.194200   \n",
       "std       0.500049     8.440807   9900.083569        1.091387   \n",
       "min       0.000000    18.000000   5300.000000        0.000000   \n",
       "25%       0.000000    24.000000  33300.000000        0.000000   \n",
       "50%       0.000000    30.000000  40200.000000        1.000000   \n",
       "75%       1.000000    37.000000  46600.000000        2.000000   \n",
       "max       1.000000    65.000000  79000.000000        6.000000   \n",
       "\n",
       "       insurance_benefits  \n",
       "count         5000.000000  \n",
       "mean             0.148000  \n",
       "std              0.463183  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              5.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "plt.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the data:\n",
    "    - We find no null or missing values\n",
    "    - Each series has a proper data type\n",
    "    - Nothing abnormal about the distributions\n",
    "        - Age has a strong right tail\n",
    "        - Salary is quite normal looking\n",
    "        - Gender is binary\n",
    "        - family_member and insurance_benefits are somewhat similar looking but the first has a stronger tail while the latter is heavily favored over 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Provide a theoretical proof based on the equation of linear regression.\n",
    "- The features are multiplied by an invertible matrix.\n",
    "- Show that the quality of the model is the same for both sets of parameters: the original features and the features after multiplication.\n",
    "- How are the weight vectors from MSE minimums for these models related?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theoretical Proof:**\n",
    "- Linear regression equation --> y = wx + $w_{0}$\n",
    "- We want to find a prediction vector (a) so we take the training features (X) and get --> a = Xw + $w_{0}$\n",
    "- By creating columnb zero in matrix X and setting it to all 1's we can multiply it by the w vector to get --> a = Xw\n",
    "- Now we can find the w vector that minimizes MSE with --> w = argmin MSE(Xw, y), where y is the target vector\n",
    "- This is also completed with the formula --> w = $($X^{T}$X)^{-1}$$X^{T}$y\n",
    "\n",
    "- With the inverted random matrix as the key, it is multiplied with the original feature set to to create new features.\n",
    "- With a different feature set that was changed with the inverted matrix, the formula is used to minimize MSE and get the same result based on new weight vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-22222.379666</td>\n",
       "      <td>27153.853364</td>\n",
       "      <td>5329.791264</td>\n",
       "      <td>23965.204681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-17047.881538</td>\n",
       "      <td>20820.256106</td>\n",
       "      <td>4080.156869</td>\n",
       "      <td>18360.027364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-9424.382291</td>\n",
       "      <td>11508.276917</td>\n",
       "      <td>2252.440093</td>\n",
       "      <td>10146.108076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-18668.988600</td>\n",
       "      <td>22817.703122</td>\n",
       "      <td>4488.575274</td>\n",
       "      <td>20148.819235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-11700.267417</td>\n",
       "      <td>14294.040378</td>\n",
       "      <td>2800.911578</td>\n",
       "      <td>12610.416497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1            2             3\n",
       "0 -22222.379666  27153.853364  5329.791264  23965.204681\n",
       "1 -17047.881538  20820.256106  4080.156869  18360.027364\n",
       "2  -9424.382291  11508.276917  2252.440093  10146.108076\n",
       "3 -18668.988600  22817.703122  4488.575274  20148.819235\n",
       "4 -11700.267417  14294.040378  2800.911578  12610.416497"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop('insurance_benefits', axis=1)\n",
    "target = df['insurance_benefits']\n",
    "\n",
    "# invertible matrix to multiply by features\n",
    "rand_matrix = np.random.normal(size=(4,4))\n",
    "rand_m_inv = np.linalg.inv(rand_matrix)\n",
    "\n",
    "# matrix multiplication between original features and random inverted matrix\n",
    "new_features = features @ rand_m_inv\n",
    "new_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data for training and testing for each set\n",
    "xtrain, xval, ytrain, yval = train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "x1_train, x1_val, y1_train, y1_val = train_test_split(new_features, target, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data R2 Score: 0.36249729353277194\n",
      "MSE: 0.1086043235710505\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(xtrain, ytrain)\n",
    "preds = model.predict(xval)\n",
    "score = r2_score(yval, preds)\n",
    "mse = mean_squared_error(yval, preds)\n",
    "print('Original Data R2 Score:', score)\n",
    "print('MSE:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplied Data R2 Score: 0.3624972935327553\n",
      "MSE: 0.10860432357105333\n"
     ]
    }
   ],
   "source": [
    "model_1 = LinearRegression()\n",
    "model_1.fit(x1_train, y1_train)\n",
    "preds_1 = model_1.predict(x1_val)\n",
    "score_1 = r2_score(y1_val, preds_1)\n",
    "mse_1 = mean_squared_error(y1_val, preds_1)\n",
    "print('Multiplied Data R2 Score:', score_1)\n",
    "print('MSE:', mse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarity of Models with different Features**\n",
    "- Based on training and running a Linear Regression model on both the original data and the transformed data:\n",
    "    - Both sets score the exact same in R2 score up to the 11th decimal place\n",
    "    - Both sets score the exact same MSE up to the 12th decimal place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Feature Weights: [-4.43854686e-02  2.33356224e-02 -1.17739038e-05 -4.55168125e-02]\n",
      "New Feature Weights: [-0.06548293 -0.0714228  -0.0309316   0.02709593]\n",
      "-----\n",
      "Difference between weights: [-0.02109746 -0.09475842 -0.03091983  0.07261274]\n"
     ]
    }
   ],
   "source": [
    "X = features\n",
    "y = target\n",
    "w = np.linalg.inv((X.T.dot(X))).dot(X.T).dot(y)\n",
    "\n",
    "X1 = new_features\n",
    "w1 = np.linalg.inv((X1.T.dot(X1))).dot(X1.T).dot(y)\n",
    "\n",
    "print('Original Feature Weights:', w)\n",
    "print('New Feature Weights:', w1)\n",
    "print('-----')\n",
    "print('Difference between weights:', w1-w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing weights of the two feature sets**\n",
    "- Using the formula to calculate the weight vectors from MSE minimums:\n",
    "    - We see slight differences between the two weight vectors\n",
    "    - For the transformed data vs the original:\n",
    "        - The gender column is weighted more\n",
    "        - The age column is weighted less\n",
    "        - The salary column is weighted less\n",
    "        - The family_member column is weighted more\n",
    "    - The two feature sets score the same R2 and MSE with slightly different vectors because the feature values are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) State an algorithm for data transformation to solve the task. \n",
    "- Explain why the linear regression quality won't change based on the proof above.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The way we can transform data is by creating a random square matrix where both the numbers and rows are equal to the number of columns in the original feature set\n",
    "- We can then invert the randomly created matrix and multiply it by the original matrix to create a new masked feature set\n",
    "    - This feature set completely changes each number so we do not know the actual values of gender, age, salary, or number of family members\n",
    "- We can then train and test our Linear Regression model on the new features without revealing any potential information.\n",
    "---\n",
    "- Based on the proof in the prior section, both the original features from the data as well as the masked data gets us the same metric results in both R2 Score and MSE.\n",
    "    - Since each datapoint is masked with the same random matrix, the model will not see major differences between the two and will predict the same way\n",
    "    - The only things that change are the weights of the features, because they were transformed, but need to get to the same result in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Program your algorithm using matrix operations. \n",
    "- Make sure that the quality of linear regression from sklearn is the same before and after transformation. Use the R2 metric.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    def mask(self, train_features):\n",
    "        rand_matrix = np.random.normal(size=(train_features.shape[1], train_features.shape[1]))\n",
    "        rand_m_inv = np.linalg.inv(rand_matrix)\n",
    "        new_features = train_features @ rand_m_inv\n",
    "        return new_features\n",
    "    \n",
    "    def split(self, features, target, new_features):\n",
    "        xt, xv, yt, yv = train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "        xt1, xv1, yt1, yv1 = train_test_split(new_features, target, test_size=0.2, random_state=1)\n",
    "        return xt, xv, yt, yv, xt1, xv1, yt1, yv1\n",
    "    \n",
    "    def fit(self, train_features, train_target):\n",
    "        X = np.concatenate((np.ones((train_features.shape[0], 1)), train_features), axis=1)\n",
    "        y = train_target\n",
    "        w = np.linalg.inv((X.T.dot(X))).dot(X.T).dot(y)\n",
    "        self.w = w[1:]\n",
    "        self.w0 = w[0]\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        return test_features.dot(self.w) + self.w0\n",
    "    \n",
    "    def score_diff(self, original_score, mask_score):\n",
    "        return mask_score - original_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data R2: 0.36249729353277327\n",
      "Transform Data R2: 0.36249731162493115\n",
      "-----\n",
      " Difference between R2 Scores: 1.809215788295404e-08\n",
      "\n",
      "Original Data MSE: 0.10860432357105027\n",
      "Transform Data MSE: 0.10860432048888835\n",
      "-----\n",
      " Difference between MSE Scores: -3.082161914580439e-09\n"
     ]
    }
   ],
   "source": [
    "# Initiate model\n",
    "mod = LinReg()\n",
    "mod1 = LinReg()\n",
    "\n",
    "# Create transformed features\n",
    "transformed_feats = mod1.mask(features)\n",
    "\n",
    "# Split data into train and test\n",
    "xt, xv, yt, yv, xt1, xv1, yt1, yv1 = mod.split(features, target, transformed_feats)\n",
    "\n",
    "# Fit, Predict, and Score original dataset\n",
    "mod.fit(xt, yt)\n",
    "p = mod.predict(xv)\n",
    "r = r2_score(yv, p)\n",
    "m = mean_squared_error(yv, p)\n",
    "\n",
    "# Fit, Predict, and Score transformed dataset\n",
    "mod1.fit(xt1, yt1)\n",
    "p1 = mod1.predict(xv1)\n",
    "r1 = r2_score(yv1, p1)\n",
    "m1 = mean_squared_error(yv1, p1)\n",
    "\n",
    "# Find difference between the R2 Scores\n",
    "diff = mod.score_diff(r, r1)\n",
    "mse_diff = mod.score_diff(m, m1)\n",
    "\n",
    "print('Original Data R2:', r)\n",
    "print('Transform Data R2:', r1)\n",
    "print('-----')\n",
    "print(' Difference between R2 Scores:', diff)\n",
    "print('')\n",
    "print('Original Data MSE:', m)\n",
    "print('Transform Data MSE:', m1)\n",
    "print('-----')\n",
    "print(' Difference between MSE Scores:', mse_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- Above I created the LinReg class:\n",
    "    - Under this I created all of the necessary functions to transform the features, split the data, fit the model, train the model, score the model, and compare it to a the transformed model.\n",
    "- After running this algorithm, I found a similar result in that the original and transformed data both allow the model to return a nearly identical result up to the 8th decimal\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
